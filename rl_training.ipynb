{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gymnasium in ./.venv/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./.venv/lib/python3.11/site-packages (from gymnasium) (2.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./.venv/lib/python3.11/site-packages (from gymnasium) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in ./.venv/lib/python3.11/site-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in ./.venv/lib/python3.11/site-packages (from gymnasium) (0.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.11/site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.11/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.venv/lib/python3.11/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.11/site-packages (0.20.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: torch==2.5.1 in ./.venv/lib/python3.11/site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.11/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install gymnasium\n",
    "%pip install torch\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 25 19:21:16 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX 2000 Ada Gene...    On  |   00000000:82:00.0 Off |                  Off |\n",
      "| 30%   24C    P8              7W /   70W |       2MiB /  16380MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from tools.scopa_env import *\n",
    "from tools.scopone_scientifico_sim import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing on cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "print(f'Playing on {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ScopaEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        print(f'Creating DQN with {n_observations} observations and {n_actions} actions')\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DQN with 120 observations and 40 actions\n",
      "Creating DQN with 120 observations and 40 actions\n"
     ]
    }
   ],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = 40\n",
    "# Get the number of state observations\n",
    "state = env.reset()\n",
    "state = state.flatten()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state, player):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "\n",
    "    pred = []\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            pred = policy_net(state.flatten()).detach().cpu().numpy()\n",
    "    else:\n",
    "        pred = env.action_space.sample()[0]\n",
    "\n",
    "    \n",
    "    actionset = pd.DataFrame(np.array(pred))\n",
    "    actionset = actionset.sort_values(by=0, ascending=True)\n",
    "\n",
    "    return actionset\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    #print(f'state_batch: {state_batch.shape}, action_batch: {action_batch.shape}, reward_batch: {reward_batch.shape}')\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch.view(BATCH_SIZE, n_actions))\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(-1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 9/10: 9it [00:00, 102.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqZ0lEQVR4nO3dfXjMd77/8dckJBlpEuImN6TETZe6LSFF6lCpVFvE6ra6toKqs0pJg650j7tiU3qqjuVQtpVtabVVto7usjbdS0qVYKPUbYm6S4KSjKQVmnzPH36d35kKlUgyE5/n47rmujrf73y/8x45e+V5vvOZic2yLEsAAAAG8XL3AAAAAFWNAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACgDKy2WyaPn26u8cAcBsIIAAeJzU1VTabzXmrUaOGGjZsqGHDhun06dPuHu86n3/+uaZPn668vDx3jwLgFtVw9wAAcCMvv/yyIiMjdfnyZX3xxRdKTU3Vli1btG/fPvn5+bl7PKfPP/9cM2bM0LBhw1S7dm13jwPgFhBAADxW3759FRUVJUkaOXKk6tWrpzlz5mjdunV64okn3DwdgOqMt8AAVBsPPPCAJOno0aPObQcPHtTjjz+u4OBg+fn5KSoqSuvWrXM57urVq5oxY4ZatGghPz8/1a1bVzExMdq0aZPzMT179lTPnj2ve85hw4apSZMmN5xp+vTpmjRpkiQpMjLS+bbd8ePHy/9CAVQ6rgABqDZ+jIo6depIkr766it1795dDRs21OTJk+Xv768PPvhA8fHx+uijjzRw4EBJ1yIlJSVFI0eOVJcuXeRwOLRz507t3r1bDz300G3N9Mtf/lKHDx/We++9p9dff1316tWTJNWvX/+2zgugchFAADxWfn6+zp8/r8uXL2v79u2aMWOGfH199dhjj0mSxo8fr7vvvlsZGRny9fWVJD333HOKiYnR7373O2cAffLJJ3rkkUe0dOnSCp+xXbt26tixo9577z3Fx8ff9GoRAM/BW2AAPFZsbKzq16+viIgIPf744/L399e6devUqFEjXbhwQZ9++qmeeOIJXbp0SefPn9f58+f17bffKi4uTkeOHHF+Yqx27dr66quvdOTIETe/IgCeggAC4LEWLVqkTZs2afXq1XrkkUd0/vx555Wer7/+WpZlacqUKapfv77Lbdq0aZKks2fPSrr2abK8vDzdc889atu2rSZNmqQvv/zSba8LgPvxFhgAj9WlSxfnp8Di4+MVExOjX//61zp06JBKSkokSRMnTlRcXFypxzdv3lyS1KNHDx09elQff/yx/v73v+tPf/qTXn/9dS1ZskQjR46UdO3LDS3Luu4cxcXFlfHSALgZAQSgWvD29lZKSop69eqlhQsXasSIEZKkmjVrKjY29mePDw4O1vDhwzV8+HAVFBSoR48emj59ujOA6tSpo2PHjl133DfffPOz57bZbGV8NQDcjbfAAFQbPXv2VJcuXTR//nwFBgaqZ8+eeuONN5SdnX3dY8+dO+f872+//dZl31133aXmzZurqKjIua1Zs2Y6ePCgy3F79uzR1q1bf3Yuf39/SeKboIFqhCtAAKqVSZMm6Ve/+pVSU1O1aNEixcTEqG3btnr22WfVtGlT5ebmatu2bTp16pT27NkjSbr33nvVs2dPderUScHBwdq5c6dWr16tsWPHOs87YsQIzZs3T3FxcXrmmWd09uxZLVmyRK1bt5bD4bjpTJ06dZIk/f73v9fgwYNVs2ZN9evXzxlGADyQBQAeZvny5ZYkKyMj47p9xcXFVrNmzaxmzZpZP/zwg3X06FFr6NChVmhoqFWzZk2rYcOG1mOPPWatXr3aecysWbOsLl26WLVr17bsdrvVsmVLa/bs2daVK1dczr1ixQqradOmlo+Pj9WhQwdr48aNVkJCgtW4cWOXx0mypk2b5rJt5syZVsOGDS0vLy9LkpWVlVVR/xwAKoHNskpZ9QcAAHAHYw0QAAAwDgEEAACMQwABAADjEEAAAMA4BBAAADAOAQQAAIzDFyGWoqSkRGfOnFFAQABfcQ8AQDVhWZYuXbqk8PBweXnd/BoPAVSKM2fOKCIiwt1jAACAcjh58qQaNWp008cQQKUICAiQdO0fMDAw0M3TAACAW+FwOBQREeH8PX4zBFApfnzbKzAwkAACAKCauZXlKyyCBgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGActwZQenq6+vXrp/DwcNlsNv3lL39x2W9ZlqZOnaqwsDDZ7XbFxsbqyJEjt3z+V155RTabTYmJiRU7OAAAqNbcGkCFhYVq3769Fi1aVOr+uXPnasGCBVqyZIm2b98uf39/xcXF6fLlyz977oyMDL3xxhtq165dRY8NAACqObcGUN++fTVr1iwNHDjwun2WZWn+/Pn6j//4Dw0YMEDt2rXT22+/rTNnzlx3peinCgoKNGTIEC1btkx16tSppOkBAEB15bFrgLKyspSTk6PY2FjntqCgIEVHR2vbtm03PXbMmDF69NFHXY4FAAD4UQ13D3AjOTk5kqSQkBCX7SEhIc59pVm1apV2796tjIyMW36uoqIiFRUVOe87HI4yTgsAAKoTj70CVB4nT57U+PHjtXLlSvn5+d3ycSkpKQoKCnLeIiIiKnFKAADgbh4bQKGhoZKk3Nxcl+25ubnOfT+1a9cunT17Vh07dlSNGjVUo0YNbd68WQsWLFCNGjVUXFxc6nHJycnKz8933k6ePFmxLwYAAHgUj30LLDIyUqGhoUpLS1OHDh0kXXtravv27Ro9enSpx/Tu3Vt79+512TZ8+HC1bNlSv/vd7+Tt7V3qcb6+vvL19a3Q+QEAgOdyawAVFBTo66+/dt7PyspSZmamgoODdffddysxMVGzZs1SixYtFBkZqSlTpig8PFzx8fHOY3r37q2BAwdq7NixCggIUJs2bVyew9/fX3Xr1r1uOwAAMJdbA2jnzp3q1auX835SUpIkKSEhQampqXrxxRdVWFioUaNGKS8vTzExMdqwYYPL+p6jR4/q/PnzVT47AACovmyWZVnuHsLTOBwOBQUFKT8/X4GBge4eBwAA3IKy/P722EXQAAAAlYUAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGActwZQenq6+vXrp/DwcNlsNv3lL39x2W9ZlqZOnaqwsDDZ7XbFxsbqyJEjNz1nSkqKOnfurICAADVo0EDx8fE6dOhQJb4KAABQ3bg1gAoLC9W+fXstWrSo1P1z587VggULtGTJEm3fvl3+/v6Ki4vT5cuXb3jOzZs3a8yYMfriiy+0adMmXb16VX369FFhYWFlvQwAAFDN2CzLstw9hCTZbDatXbtW8fHxkq5d/QkPD9eECRM0ceJESVJ+fr5CQkKUmpqqwYMH39J5z507pwYNGmjz5s3q0aPHLR3jcDgUFBSk/Px8BQYGluv1AACAqlWW398euwYoKytLOTk5io2NdW4LCgpSdHS0tm3bdsvnyc/PlyQFBwdX+IwAAKB6quHuAW4kJydHkhQSEuKyPSQkxLnv55SUlCgxMVHdu3dXmzZtbvi4oqIiFRUVOe87HI5yTAwAAKoLj70CVBHGjBmjffv2adWqVTd9XEpKioKCgpy3iIiIKpoQAAC4g8cGUGhoqCQpNzfXZXtubq5z382MHTtW69ev1z//+U81atTopo9NTk5Wfn6+83by5MnyDw4AADyexwZQZGSkQkNDlZaW5tzmcDi0fft2de3a9YbHWZalsWPHau3atfr0008VGRn5s8/l6+urwMBAlxsAALhzuXUNUEFBgb7++mvn/aysLGVmZio4OFh33323EhMTNWvWLLVo0UKRkZGaMmWKwsPDnZ8Uk6TevXtr4MCBGjt2rKRrb3u9++67+vjjjxUQEOBcLxQUFCS73V6lrw8AAHgmtwbQzp071atXL+f9pKQkSVJCQoJSU1P14osvqrCwUKNGjVJeXp5iYmK0YcMG+fn5OY85evSozp8/77y/ePFiSVLPnj1dnmv58uUaNmxY5b0YAABQbXjM9wB5Er4HCACA6ueO+B4gAACAykIAAQAA4xBAAADAOAQQAAAwDgEEAACMQwABAADjEEAAAMA4BBAAADAOAQQAAIxDAAEAAOMQQAAAwDgEEAAAMA4BBAAAjEMAAQAA4xBAAADAOAQQAAAwDgEEAACMQwABAADjEEAAAMA4BBAAADAOAQQAAIxDAAEAAOMQQAAAwDgEEAAAMA4BBAAAjEMAAQAA4xBAAADAOAQQAAAwDgEEAACMQwABAADjEEAAAMA4BBAAADAOAQQAAIxDAAEAAOPUKO+BeXl52rFjh86ePauSkhKXfUOHDr3twQAAACpLuQLof/7nfzRkyBAVFBQoMDBQNpvNuc9msxFAAADAo5XrLbAJEyZoxIgRKigoUF5eni5evOi8XbhwoaJnBAAAqFDlCqDTp09r3LhxqlWrVkXPAwAAUOnKFUBxcXHauXNnRc8CAABQJcq1BujRRx/VpEmTtH//frVt21Y1a9Z02d+/f/8KGQ4AAKAy2CzLssp6kJfXjS8c2Ww2FRcX39ZQ7uZwOBQUFKT8/HwFBga6exwAAHALyvL7u1xXgH76sXcAAIDqhC9CBAAAxil3AG3evFn9+vVT8+bN1bx5c/Xv31+fffZZRc4GAABQKcoVQCtWrFBsbKxq1aqlcePGady4cbLb7erdu7fefffdip4RAACgQpVrEXSrVq00atQovfDCCy7b582bp2XLlunAgQMVNqA7sAgaAIDqpyy/v8t1BejYsWPq16/fddv79++vrKys8pwSAACgypQrgCIiIpSWlnbd9n/84x+KiIi47aEAAAAqU7k+Bj9hwgSNGzdOmZmZ6tatmyRp69atSk1N1X/9139V6IAAAAAVrVwBNHr0aIWGhuq1117TBx98IOnauqD3339fAwYMqNABAQAAKlq5FkHf6VgEDQBA9VPpi6ABAACqs1t+Cyw4OFiHDx9WvXr1VKdOHdlsths+9sKFCxUyHAAAQGW45QB6/fXXFRAQ4PzvmwUQAACAJ2MNUClYAwQAQPVT6WuAvL29dfbs2eu2f/vtt/L29i7PKQEAAKpMuQLoRheNioqK5OPjc1sDAQAAVLYyfQ/QggULJEk2m01/+tOfdNdddzn3FRcXKz09XS1btrzl86Wnp+vVV1/Vrl27lJ2drbVr1yo+Pt6537IsTZs2TcuWLVNeXp66d++uxYsXq0WLFjc976JFi/Tqq68qJydH7du31x//+Ed16dKlLC8VAADcwcoUQK+//rqka2GyZMkSl7e7fHx81KRJEy1ZsuSWz1dYWKj27dtrxIgR+uUvf3nd/rlz52rBggX685//rMjISE2ZMkVxcXHav3+//Pz8Sj3n+++/r6SkJC1ZskTR0dGaP3++4uLidOjQITVo0KAsLxcAANyhyrUIulevXlqzZo3q1KlTcYPYbC5XgCzLUnh4uCZMmKCJEydKkvLz8xUSEqLU1FQNHjy41PNER0erc+fOWrhwoSSppKREERERev755zV58uRbmqWyFkFblqXvrxZX2PkAAKiu7DW9K/wT5WX5/V2uP4Xxz3/+s1yDlUVWVpZycnIUGxvr3BYUFKTo6Ght27at1AC6cuWKdu3apeTkZOc2Ly8vxcbGatu2bTd8rqKiIhUVFTnvOxyOCnoVrr6/Wqx7p26slHMDAFCd7H85TrV8ypUhFaLcz3zq1CmtW7dOJ06c0JUrV1z2zZs377YHy8nJkSSFhIS4bA8JCXHu+6nz58+ruLi41GMOHjx4w+dKSUnRjBkzbnNiAABQXZQrgNLS0tS/f381bdpUBw8eVJs2bXT8+HFZlqWOHTtW9IyVLjk5WUlJSc77DodDERERFf489pre2v9yXIWfFwCA6sZe071fm1OuAEpOTtbEiRM1Y8YMBQQE6KOPPlKDBg00ZMgQPfzwwxUyWGhoqCQpNzdXYWFhzu25ubnq0KFDqcfUq1dP3t7eys3Nddmem5vrPF9pfH195evre/tD/wybzebWy30AAOCacn0P0IEDBzR06FBJUo0aNfT999/rrrvu0ssvv6w5c+ZUyGCRkZEKDQ1VWlqac5vD4dD27dvVtWvXUo/x8fFRp06dXI4pKSlRWlraDY8BAADmKVcA+fv7O9f9hIWF6ejRo85958+fv+XzFBQUKDMzU5mZmZKuLXzOzMzUiRMnZLPZlJiYqFmzZmndunXau3evhg4dqvDwcJfvCurdu7fzE1+SlJSUpGXLlunPf/6zDhw4oNGjR6uwsFDDhw8vz0sFAAB3oHK9H3P//fdry5YtatWqlR555BFNmDBBe/fu1Zo1a3T//fff8nl27typXr16Oe//uA4nISFBqampevHFF1VYWKhRo0YpLy9PMTEx2rBhg8t3AB09etQlup588kmdO3dOU6dOVU5Ojjp06KANGzZctzAaAACYq1zfA3Ts2DEVFBSoXbt2Kiws1IQJE/T555+rRYsWmjdvnho3blwZs1YZ/hgqAADVT6V+D1BxcbFOnTqldu3aSbr2dlhZvv0ZAADA3cq8Bsjb21t9+vTRxYsXK2MeAACASleuRdBt2rTRsWPHKnoWAACAKlGuAJo1a5YmTpyo9evXKzs7Ww6Hw+UGAADgycq1CNrL6/930//9Q2aWZclms6m4uHr/wU8WQQMAUP3cEX8MFQAAoLKUK4D+7d/+raLnAAAAqDLlCqD09PSb7u/Ro0e5hgEAAKgK5Qqgnj17Xrft/64Fqu5rgAAAwJ2tXJ8Cu3jxosvt7Nmz2rBhgzp37qy///3vFT0jAABAhSrXFaCgoKDrtj300EPy8fFRUlKSdu3adduDAQAAVJZyXQG6kZCQEB06dKgiTwkAAFDhynUF6Msvv3S5b1mWsrOz9corr6hDhw4VMRcAAEClKVcAdejQQTabTT/9DsX7779fb731VoUMBgAAUFnKFUBZWVku9728vFS/fn35+flVyFAAAACVqcwBVFJSorS0NK1Zs0bHjx+XzWZTZGSkHn/8cT399NMuH4cHAADwRGVaBG1Zlvr376+RI0fq9OnTatu2rVq3bq1vvvlGw4YN08CBAytrTgAAgApTpitAqampSk9PV1pamnr16uWy79NPP1V8fLzefvttDR06tEKHBAAAqEhlugL03nvv6aWXXroufiTpwQcf1OTJk7Vy5coKGw4AAKAylCmAvvzySz388MM33N+3b1/t2bPntocCAACoTGUKoAsXLigkJOSG+0NCQnTx4sXbHgoAAKAylSmAiouLVaPGjZcNeXt764cffrjtoQAAACpTmRZBW5alYcOGydfXt9T9RUVFFTIUAABAZSpTACUkJPzsY/gEGAAA8HRlCqDly5dX1hwAAABVpkL/GjwAAEB1QAABAADjEEAAAMA4BBAAADAOAQQAAIxDAAEAAOMQQAAAwDgEEAAAMA4BBAAAjEMAAQAA4xBAAADAOAQQAAAwDgEEAACMQwABAADjEEAAAMA4BBAAADAOAQQAAIxDAAEAAOMQQAAAwDgEEAAAMA4BBAAAjEMAAQAA4xBAAADAOAQQAAAwDgEEAACMQwABAADjEEAAAMA4BBAAADAOAQQAAIxDAAEAAOMQQAAAwDgeH0CXLl1SYmKiGjduLLvdrm7duikjI+Omx6xcuVLt27dXrVq1FBYWphEjRujbb7+tookBAICn8/gAGjlypDZt2qR33nlHe/fuVZ8+fRQbG6vTp0+X+vitW7dq6NCheuaZZ/TVV1/pww8/1I4dO/Tss89W8eQAAMBTeXQAff/99/roo480d+5c9ejRQ82bN9f06dPVvHlzLV68uNRjtm3bpiZNmmjcuHGKjIxUTEyM/v3f/107duyo4ukBAICn8ugA+uGHH1RcXCw/Pz+X7Xa7XVu2bCn1mK5du+rkyZP661//KsuylJubq9WrV+uRRx654fMUFRXJ4XC43AAAwJ3LowMoICBAXbt21cyZM3XmzBkVFxdrxYoV2rZtm7Kzs0s9pnv37lq5cqWefPJJ+fj4KDQ0VEFBQVq0aNENnyclJUVBQUHOW0RERGW9JAAA4AE8OoAk6Z133pFlWWrYsKF8fX21YMECPfXUU/LyKn30/fv3a/z48Zo6dap27dqlDRs26Pjx4/rtb397w+dITk5Wfn6+83by5MnKejkAAMAD2CzLstw9xK0oLCyUw+FQWFiYnnzySRUUFOiTTz657nFPP/20Ll++rA8//NC5bcuWLXrggQd05swZhYWF/exzORwOBQUFKT8/X4GBgRX6OgAAQOUoy+9vj78C9CN/f3+FhYXp4sWL2rhxowYMGFDq47777rvrrg55e3tLkqpJ6wEAgErm8QG0ceNGbdiwQVlZWdq0aZN69eqlli1bavjw4ZKuvX01dOhQ5+P79eunNWvWaPHixTp27Ji2bt2qcePGqUuXLgoPD3fXywAAAB6khrsH+Dn5+flKTk7WqVOnFBwcrEGDBmn27NmqWbOmJCk7O1snTpxwPn7YsGG6dOmSFi5cqAkTJqh27dp68MEHNWfOHHe9BAAA4GGqzRqgqsQaIAAAqp87cg0QAABARSGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgAAAgHEIIAAAYBwCCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABjH4wPo0qVLSkxMVOPGjWW329WtWzdlZGTc9JiioiL9/ve/V+PGjeXr66smTZrorbfeqqKJAQCAp6vh7gF+zsiRI7Vv3z698847Cg8P14oVKxQbG6v9+/erYcOGpR7zxBNPKDc3V2+++aaaN2+u7OxslZSUVPHkAADAU9ksy7LcPcSNfP/99woICNDHH3+sRx991Lm9U6dO6tu3r2bNmnXdMRs2bNDgwYN17NgxBQcHl+t5HQ6HgoKClJ+fr8DAwHLPDwAAqk5Zfn979FtgP/zwg4qLi+Xn5+ey3W63a8uWLaUes27dOkVFRWnu3Llq2LCh7rnnHk2cOFHff//9DZ+nqKhIDofD5QYAAO5cHh1AAQEB6tq1q2bOnKkzZ86ouLhYK1as0LZt25SdnV3qMceOHdOWLVu0b98+rV27VvPnz9fq1av13HPP3fB5UlJSFBQU5LxFRERU1ksCAAAewKPfApOko0ePasSIEUpPT5e3t7c6duyoe+65R7t27dKBAweue3yfPn302WefKScnR0FBQZKkNWvW6PHHH1dhYaHsdvt1xxQVFamoqMh53+FwKCIigrfAAACoRu6Yt8AkqVmzZtq8ebMKCgp08uRJ7dixQ1evXlXTpk1LfXxYWJgaNmzojB9JatWqlSzL0qlTp0o9xtfXV4GBgS43AABw5/L4APqRv7+/wsLCdPHiRW3cuFEDBgwo9XHdu3fXmTNnVFBQ4Nx2+PBheXl5qVGjRlU1LgAA8GAeH0AbN27Uhg0blJWVpU2bNqlXr15q2bKlhg8fLklKTk7W0KFDnY//9a9/rbp162r48OHav3+/0tPTNWnSJI0YMaLUt78AAIB5PD6A8vPzNWbMGLVs2VJDhw5VTEyMNm7cqJo1a0qSsrOzdeLECefj77rrLm3atEl5eXmKiorSkCFD1K9fPy1YsMBdLwEAAHgYj18E7Q58DxAAANXPHbUIGgAAoKIRQAAAwDgEEAAAMA4BBAAAjEMAAQAA4xBAAADAOAQQAAAwDgEEAACMQwABAADjEEAAAMA4BBAAADAOAQQAAIxDAAEAAOMQQAAAwDgEEAAAMA4BBAAAjEMAAQAA4xBAAADAOAQQAAAwDgEEAACMQwABAADjEEAAAMA4BBAAADAOAQQAAIxDAAEAAOMQQAAAwDgEEAAAMA4BBAAAjEMAAQAA4xBAAADAOAQQAAAwDgEEAACMQwABAADjEEAAAMA4BBAAADAOAQQAAIxDAAEAAOMQQAAAwDgEEAAAMA4BBAAAjEMAAQAA4xBAAADAOAQQAAAwTg13D+CJLMuSJDkcDjdPAgAAbtWPv7d//D1+MwRQKS5duiRJioiIcPMkAACgrC5duqSgoKCbPsZm3UomGaakpERnzpxRQECAbDZbhZ7b4XAoIiJCJ0+eVGBgYIWeG2XHz8Oz8PPwLPw8PAs/j59nWZYuXbqk8PBweXndfJUPV4BK4eXlpUaNGlXqcwQGBvJ/wB6En4dn4efhWfh5eBZ+Hjf3c1d+fsQiaAAAYBwCCAAAGIcAqmK+vr6aNm2afH193T0KxM/D0/Dz8Cz8PDwLP4+KxSJoAABgHK4AAQAA4xBAAADAOAQQAAAwDgEEAACMQwBVoUWLFqlJkyby8/NTdHS0duzY4e6RjJSSkqLOnTsrICBADRo0UHx8vA4dOuTusfD/vPLKK7LZbEpMTHT3KEY7ffq0fvOb36hu3bqy2+1q27atdu7c6e6xjFRcXKwpU6YoMjJSdrtdzZo108yZM2/p713hxgigKvL+++8rKSlJ06ZN0+7du9W+fXvFxcXp7Nmz7h7NOJs3b9aYMWP0xRdfaNOmTbp69ar69OmjwsJCd49mvIyMDL3xxhtq166du0cx2sWLF9W9e3fVrFlTf/vb37R//3699tprqlOnjrtHM9KcOXO0ePFiLVy4UAcOHNCcOXM0d+5c/fGPf3T3aNUaH4OvItHR0ercubMWLlwo6drfG4uIiNDzzz+vyZMnu3k6s507d04NGjTQ5s2b1aNHD3ePY6yCggJ17NhR//3f/61Zs2apQ4cOmj9/vrvHMtLkyZO1detWffbZZ+4eBZIee+wxhYSE6M0333RuGzRokOx2u1asWOHGyao3rgBVgStXrmjXrl2KjY11bvPy8lJsbKy2bdvmxskgSfn5+ZKk4OBgN09itjFjxujRRx91+d8J3GPdunWKiorSr371KzVo0ED33Xefli1b5u6xjNWtWzelpaXp8OHDkqQ9e/Zoy5Yt6tu3r5snq974Y6hV4Pz58youLlZISIjL9pCQEB08eNBNU0G6diUuMTFR3bt3V5s2bdw9jrFWrVql3bt3KyMjw92jQNKxY8e0ePFiJSUl6aWXXlJGRobGjRsnHx8fJSQkuHs840yePFkOh0MtW7aUt7e3iouLNXv2bA0ZMsTdo1VrBBCMNmbMGO3bt09btmxx9yjGOnnypMaPH69NmzbJz8/P3eNA1/4fg6ioKP3hD3+QJN13333at2+flixZQgC5wQcffKCVK1fq3XffVevWrZWZmanExESFh4fz87gNBFAVqFevnry9vZWbm+uyPTc3V6GhoW6aCmPHjtX69euVnp6uRo0auXscY+3atUtnz55Vx44dnduKi4uVnp6uhQsXqqioSN7e3m6c0DxhYWG69957Xba1atVKH330kZsmMtukSZM0efJkDR48WJLUtm1bffPNN0pJSSGAbgNrgKqAj4+POnXqpLS0NOe2kpISpaWlqWvXrm6czEyWZWns2LFau3atPv30U0VGRrp7JKP17t1be/fuVWZmpvMWFRWlIUOGKDMzk/hxg+7du1/31RCHDx9W48aN3TSR2b777jt5ebn+uvb29lZJSYmbJrozcAWoiiQlJSkhIUFRUVHq0qWL5s+fr8LCQg0fPtzdoxlnzJgxevfdd/Xxxx8rICBAOTk5kqSgoCDZ7XY3T2eegICA69Zf+fv7q27duqzLcpMXXnhB3bp10x/+8Ac98cQT2rFjh5YuXaqlS5e6ezQj9evXT7Nnz9bdd9+t1q1b61//+pfmzZunESNGuHu0ao2PwVehhQsX6tVXX1VOTo46dOigBQsWKDo62t1jGcdms5W6ffny5Ro2bFjVDoNS9ezZk4/Bu9n69euVnJysI0eOKDIyUklJSXr22WfdPZaRLl26pClTpmjt2rU6e/aswsPD9dRTT2nq1Kny8fFx93jVFgEEAACMwxogAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABiHAAIAAMYhgADcMY4fPy6bzabMzMxKe45hw4YpPj6+0s4PoGoQQAA8xrBhw2Sz2a67Pfzww7d0fEREhLKzs/kTGgB+Fn8LDIBHefjhh7V8+XKXbb6+vrd0rLe3t0JDQytjLAB3GK4AAfAovr6+Cg0NdbnVqVNH0rW/47Z48WL17dtXdrtdTZs21erVq53H/vQtsIsXL2rIkCGqX7++7Ha7WrRo4RJXe/fu1YMPPii73a66detq1KhRKigocO4vLi5WUlKSateurbp16+rFF1/UT/96UElJiVJSUhQZGSm73a727du7zATAMxFAAKqVKVOmaNCgQdqzZ4+GDBmiwYMH68CBAzd87P79+/W3v/1NBw4c0OLFi1WvXj1JUmFhoeLi4lSnTh1lZGToww8/1D/+8Q+NHTvWefxrr72m1NRUvfXWW9qyZYsuXLigtWvXujxHSkqK3n77bS1ZskRfffWVXnjhBf3mN7/R5s2bK+8fAcDtswDAQyQkJFje3t6Wv7+/y2327NmWZVmWJOu3v/2tyzHR0dHW6NGjLcuyrKysLEuS9a9//cuyLMvq16+fNXz48FKfa+nSpVadOnWsgoIC57ZPPvnE8vLysnJycizLsqywsDBr7ty5zv1Xr161GjVqZA0YMMCyLMu6fPmyVatWLevzzz93OfczzzxjPfXUU+X/hwBQ6VgDBMCj9OrVS4sXL3bZFhwc7Pzvrl27uuzr2rXrDT/1NXr0aA0aNEi7d+9Wnz59FB8fr27dukmSDhw4oPbt28vf39/5+O7du6ukpESHDh2Sn5+fsrOzFR0d7dxfo0YNRUVFOd8G+/rrr/Xdd9/poYcecnneK1eu6L777iv7iwdQZQggAB7F399fzZs3r5Bz9e3bV998843++te/atOmTerdu7fGjBmj//zP/6yQ8/+4XuiTTz5Rw4YNXfbd6sJtAO7BGiAA1coXX3xx3f1WrVrd8PH169dXQkKCVqxYofnz52vp0qWSpFatWmnPnj0qLCx0Pnbr1q3y8vLSL37xCwUFBSksLEzbt2937v/hhx+0a9cu5/17771Xvr6+OnHihJo3b+5yi4iIqKiXDKAScAUIgEcpKipSTk6Oy7YaNWo4Fy9/+OGHioqKUkxMjFauXKkdO3bozTffLPVcU6dOVadOndS6dWsVFRVp/fr1zlgaMmSIpk2bpoSEBE2fPl3nzp3T888/r6efflohISGSpPHjx+uVV15RixYt1LJlS82bN095eXnO8wcEBGjixIl64YUXVFJSopiYGOXn52vr1q0KDAxUQkJCJfwLAagIBBAAj7JhwwaFhYW5bPvFL36hgwcPSpJmzJihVatW6bnnnlNYWJjee+893XvvvaWey8fHR8nJyTp+/LjsdrseeOABrVq1SpJUq1Ytbdy4UePHj1fnzp1Vq1YtDRo0SPPmzXMeP2HCBGVnZyshIUFeXl4aMWKEBg4cqPz8fOdjZs6cqfr16yslJUXHjh1T7dq11bFjR7300ksV/U8DoALZLOsnX2oBAB7KZrNp7dq1/CkKALeNNUAAAMA4BBAAADAOa4AAVBu8Yw+gonAFCAAAGIcAAgAAxiGAAACAcQggAABgHAIIAAAYhwACAADGIYAAAIBxCCAAAGAcAggAABjnfwE9JPYY1hQ9eQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 10\n",
    "else:\n",
    "    num_episodes = 10\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    state = env.reset()\n",
    "    player = env.player\n",
    "    print(F'Player {player.__hash__()}')\n",
    "    state = torch.tensor(state.flatten(), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in tqdm(count(), desc=f'Episode {i_episode}/{num_episodes}'):\n",
    "        action = select_action(state, player)\n",
    "        print(f'Action {action.index}')\n",
    "        for i in range(0,len(action.index)):\n",
    "            if env.action_valid(action.index[i], player):\n",
    "                selected_action = action.index[i]\n",
    "                break\n",
    "            \n",
    "        if selected_action is None:\n",
    "            raise Exception(f'No valid action found. {action} | {[env.game.map_card_index(card) for card in player.hand]}')\n",
    "        observation, reward, done, _ = env.step(selected_action, player=player, v=-1)\n",
    "        #print(f'state{state} action {action} observation {observation.shape} reward{reward} terminated{done}')\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "\n",
    "        if done:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation.flatten(), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, torch.tensor(action.index, dtype=torch.int64, device=device), next_state if next_state is not None else None, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 8610505095449 has [<tools.scopone_scientifico_sim.Card object at 0x7d4c84556e10>, <tools.scopone_scientifico_sim.Card object at 0x7d4c842f5a50>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b2410>] points\n",
      "Player 8610474297689 has [<tools.scopone_scientifico_sim.Card object at 0x7d4c842f6150>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b0c10>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b0790>, <tools.scopone_scientifico_sim.Card object at 0x7d4c843d5950>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b0950>, <tools.scopone_scientifico_sim.Card object at 0x7d4cbb5415d0>, <tools.scopone_scientifico_sim.Card object at 0x7d4cbb5417d0>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b0410>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b2f50>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b01d0>, <tools.scopone_scientifico_sim.Card object at 0x7d4c843d7b90>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b36d0>, <tools.scopone_scientifico_sim.Card object at 0x7d4c843dae10>, <tools.scopone_scientifico_sim.Card object at 0x7d4c843d5b50>, <tools.scopone_scientifico_sim.Card object at 0x7d4c842f6610>] points\n",
      "Player 8610474351069 has [<tools.scopone_scientifico_sim.Card object at 0x7d4cbb541890>, <tools.scopone_scientifico_sim.Card object at 0x7d4c843d8810>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b05d0>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b1310>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b0590>, <tools.scopone_scientifico_sim.Card object at 0x7d4cbc649d10>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b07d0>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b0b10>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b10d0>, <tools.scopone_scientifico_sim.Card object at 0x7d4c843d9e50>] points\n",
      "Player 8610474350937 has [<tools.scopone_scientifico_sim.Card object at 0x7d4c844b0990>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b3390>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b0050>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b03d0>, <tools.scopone_scientifico_sim.Card object at 0x7d4c842f4b50>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b0210>, <tools.scopone_scientifico_sim.Card object at 0x7d4ca186db50>, <tools.scopone_scientifico_sim.Card object at 0x7d4c843d7650>, <tools.scopone_scientifico_sim.Card object at 0x7d4cbb542690>, <tools.scopone_scientifico_sim.Card object at 0x7d4c843d6e50>, <tools.scopone_scientifico_sim.Card object at 0x7d4c844b16d0>, <tools.scopone_scientifico_sim.Card object at 0x7d4c843d6fd0>] points\n"
     ]
    }
   ],
   "source": [
    "for player in env.game.players:\n",
    "    print(f'Player {player.__hash__()} has {player.captures} points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
